{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3.1 The Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford mustang gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>vw pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge rampage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford ranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevy s-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0    18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1    15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2    18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3    16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4    17.0          8         302.0       140.0    3449          10.5    70   \n",
       "..    ...        ...           ...         ...     ...           ...   ...   \n",
       "392  27.0          4         140.0        86.0    2790          15.6    82   \n",
       "393  44.0          4          97.0        52.0    2130          24.6    82   \n",
       "394  32.0          4         135.0        84.0    2295          11.6    82   \n",
       "395  28.0          4         120.0        79.0    2625          18.6    82   \n",
       "396  31.0          4         119.0        82.0    2720          19.4    82   \n",
       "\n",
       "     origin                       name  \n",
       "0         1  chevrolet chevelle malibu  \n",
       "1         1          buick skylark 320  \n",
       "2         1         plymouth satellite  \n",
       "3         1              amc rebel sst  \n",
       "4         1                ford torino  \n",
       "..      ...                        ...  \n",
       "392       1            ford mustang gl  \n",
       "393       2                  vw pickup  \n",
       "394       1              dodge rampage  \n",
       "395       1                ford ranger  \n",
       "396       1                 chevy s-10  \n",
       "\n",
       "[392 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto = pd.read_csv('Data/Auto.csv', na_values='?').dropna()\n",
    "Auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   599.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 10 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>7.03e-81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:47:23</td>     <th>  Log-Likelihood:    </th> <td> -1178.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2361.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   390</td>      <th>  BIC:               </th> <td>   2369.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   39.9359</td> <td>    0.717</td> <td>   55.660</td> <td> 0.000</td> <td>   38.525</td> <td>   41.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th> <td>   -0.1578</td> <td>    0.006</td> <td>  -24.489</td> <td> 0.000</td> <td>   -0.171</td> <td>   -0.145</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16.432</td> <th>  Durbin-Watson:     </th> <td>   0.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  17.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.492</td> <th>  Prob(JB):          </th> <td>0.000175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.299</td> <th>  Cond. No.          </th> <td>    322.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.606\n",
       "Model:                            OLS   Adj. R-squared:                  0.605\n",
       "Method:                 Least Squares   F-statistic:                     599.7\n",
       "Date:                Sat, 10 Apr 2021   Prob (F-statistic):           7.03e-81\n",
       "Time:                        17:47:23   Log-Likelihood:                -1178.7\n",
       "No. Observations:                 392   AIC:                             2361.\n",
       "Df Residuals:                     390   BIC:                             2369.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     39.9359      0.717     55.660      0.000      38.525      41.347\n",
       "horsepower    -0.1578      0.006    -24.489      0.000      -0.171      -0.145\n",
       "==============================================================================\n",
       "Omnibus:                       16.432   Durbin-Watson:                   0.920\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               17.305\n",
       "Skew:                           0.492   Prob(JB):                     0.000175\n",
       "Kurtosis:                       3.299   Cond. No.                         322.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "fit1 = smf.ols('mpg~horsepower', data=Auto).fit()\n",
    "(fit1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.943662938603108"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = fit1.predict(Auto)\n",
    "mean_squared_error(Auto['mpg'], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated error is 23.94 for the Linear Regression fit. Now we calculate the MSE for the quadratic and cubic regressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.55019880190998"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Auto, Auto['mpg'], test_size=0.5, random_state=2)\n",
    "\n",
    "formula = 'mpg~horsepower+I(horsepower**2)'\n",
    "fit2 = smf.ols(formula, data=X_train).fit()\n",
    "y_pred2 = fit2.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.902615007987375"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = 'mpg~horsepower+I(horsepower**3)'\n",
    "fit3 = smf.ols(formula, data=X_train).fit()\n",
    "y_pred3 = fit3.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rates for quadratic and cubic regression are 19.82 and 19.79 respectively. With different random states, we get different results as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for linear fit:  23.442643969985742\n",
      "Error for quadratic fit:  18.55019880190998\n",
      "Error for quadratic fit:  18.902615007987375\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Auto, Auto['mpg'], test_size=0.5, random_state=2)\n",
    "\n",
    "fit1 = smf.ols('mpg~horsepower', data=X_train).fit()\n",
    "y_pred = fit1.predict(X_test)\n",
    "print('Error for linear fit: ', mean_squared_error(y_test, y_pred))\n",
    "\n",
    "formula = 'mpg~horsepower+I(horsepower**2)'\n",
    "fit2 = smf.ols(formula, data=X_train).fit()\n",
    "y_pred2 = fit2.predict(X_test)\n",
    "print('Error for quadratic fit: ', mean_squared_error(y_test, y_pred2))\n",
    "\n",
    "formula = 'mpg~horsepower+I(horsepower**3)'\n",
    "fit3 = smf.ols(formula, data=X_train).fit()\n",
    "y_pred3 = fit3.predict(X_test)\n",
    "print('Error for quadratic fit: ', mean_squared_error(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that a non-linear fit performs better than a linear one. However, it is difficult to distinguish if the quadratic or cubic fit is better as the errors are very close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3.2 Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Leave-One-Out Cross-Validation (LOOCV), we calculate the error when we leave out one observation at a time. \n",
    "The LOOCV estimate for the test Mean Squared Error (MSE) is the average of these $n$ test error estimates and is given by $$CV_{(n)} = \\frac{1}{n} \\sum \\limits_{i=1}^{n} MSE_{i}$$\n",
    "\n",
    "When we use the Generalized Linear Model (GLM) function without passing Binomial to the family argument, it perfomrs linear regression.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>mpg</td>       <th>  No. Observations:  </th>  <td>   392</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   390</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Gaussian</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>       <td>identity</td>     <th>  Scale:             </th> <td>  24.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -1178.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 10 Apr 2021</td> <th>  Deviance:          </th> <td>  9385.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>17:47:29</td>     <th>  Pearson chi2:      </th> <td>9.39e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>3</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   39.9359</td> <td>    0.717</td> <td>   55.660</td> <td> 0.000</td> <td>   38.530</td> <td>   41.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th> <td>   -0.1578</td> <td>    0.006</td> <td>  -24.489</td> <td> 0.000</td> <td>   -0.170</td> <td>   -0.145</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   No. Observations:                  392\n",
       "Model:                            GLM   Df Residuals:                      390\n",
       "Model Family:                Gaussian   Df Model:                            1\n",
       "Link Function:               identity   Scale:                          24.066\n",
       "Method:                          IRLS   Log-Likelihood:                -1178.7\n",
       "Date:                Sat, 10 Apr 2021   Deviance:                       9385.9\n",
       "Time:                        17:47:29   Pearson chi2:                 9.39e+03\n",
       "No. Iterations:                     3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     39.9359      0.717     55.660      0.000      38.530      41.342\n",
       "horsepower    -0.1578      0.006    -24.489      0.000      -0.170      -0.145\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = 'mpg~horsepower'\n",
    "glm = smf.glm(formula, data=Auto)\n",
    "result = glm.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: Intercept:  [39.93586102]\n",
      "Coefficients: horsepower:  [[-0.15784473]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lm = linear_model.LinearRegression(fit_intercept=True)\n",
    "result = lm.fit(Auto['horsepower'].values.reshape(-1,1), Auto['mpg'].values.reshape(-1,1))\n",
    "print('Coefficients: Intercept: ',result.intercept_)\n",
    "print('Coefficients: horsepower: ',result.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, it is evident that the glm model and the lm(linear regression) model have similar results. \n",
    "Performing cross validation using LOOCV on the linear regression model (Cross validation using the statsmodel api would require a [wrapper](https://stackoverflow.com/questions/41045752/using-statsmodel-estimations-with-scikit-learn-cross-validation-is-it-possible) class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "X = Auto['horsepower'].values.reshape(-1,1)\n",
    "y = Auto['mpg'].values.reshape(-1,1)\n",
    "loo.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are 392 splits, i.e $n$ splits on thet data when we use LOOCV. We use the `cross_val_score` function to evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds: 392, MSE: 24.231513517929226, STD: 36.79731503640535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "crossvalidation = KFold(n_splits=loo.get_n_splits(X), random_state=None, shuffle=False)\n",
    "scores = cross_val_score(result, X, y, scoring=\"neg_mean_squared_error\", cv=crossvalidation,\n",
    " n_jobs=1)\n",
    "print(\"Folds: \" + str(len(scores)) + \", MSE: \" + str(np.mean(np.abs(scores))) + \", STD: \" + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation estimate for the error of the linear model is 24.23.\n",
    "We can also estimate the error for increasingly complex polynomial fits. \n",
    "\n",
    "Since `cross_val_score` is supported only by `sklearn` and not `statsmodels`, I transform the data into non-linear values using the `PolynomialFeatures` function from `sklearn`. Note that when I used non-linear transformations of th data using the `statsmodel` library, there was no need for an additional function, I only needed to define my polynomial term inside `I()` with the corresponding degree of polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree-1 polynomial MSE: 24.231513517929226, STD: 36.79731503640535\n",
      "Degree-2 polynomial MSE: 19.24821312448939, STD: 34.998446151782474\n",
      "Degree-3 polynomial MSE: 19.334984064114092, STD: 35.765135678007795\n",
      "Degree-4 polynomial MSE: 19.424430309411886, STD: 35.68335275769751\n",
      "Degree-5 polynomial MSE: 19.033211842978396, STD: 35.31729288251292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "for i in range(1,6):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    X_current = poly.fit_transform(X)\n",
    "    result = lm.fit(X_current, y)\n",
    "    scores = cross_val_score(result, X_current, y, scoring=\"neg_mean_squared_error\", cv=crossvalidation,\n",
    " n_jobs=1)\n",
    "    \n",
    "    print(\"Degree-\"+str(i)+\" polynomial MSE: \" + str(np.mean(np.abs(scores))) + \", STD: \" + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between linear and polynomial fits are clearly see in the MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3.3 k-Fold Cross-Validation\n",
    "\n",
    "The k-fold cross validation is similar to the Leave-One-Out-Cross-Validation, except that instead of leaving out one observation at a time, we leave out k observations at a time which serve as the test set. \n",
    "\n",
    "There exists a bias-variance tradeoff with the choice of k in kCV. The LOOCV method, where `k=1` has low bias but higher variance compared to the kCV method. \n",
    "`k=5` or `k=10` are the commonly used values as it has been proven empirically to yield test error estimates that do not have excessively high bias or variance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree-1 polynomial MSE: 27.439933652339857, STD: 14.510250711281133\n",
      "Degree-2 polynomial MSE: 21.235840055802118, STD: 11.797327528898292\n",
      "Degree-3 polynomial MSE: 21.336606183328417, STD: 11.8443397146369\n",
      "Degree-4 polynomial MSE: 21.353886994209773, STD: 11.986332342224673\n",
      "Degree-5 polynomial MSE: 20.905646119059934, STD: 12.18560440073758\n",
      "Degree-6 polynomial MSE: 20.82189095906726, STD: 12.126258882595026\n",
      "Degree-7 polynomial MSE: 20.953103378424785, STD: 12.059908521569556\n",
      "Degree-8 polynomial MSE: 21.077131510426256, STD: 12.04447106023584\n",
      "Degree-9 polynomial MSE: 21.03675183384266, STD: 11.948760351967676\n",
      "Degree-10 polynomial MSE: 20.981013741561554, STD: 11.797365253121383\n"
     ]
    }
   ],
   "source": [
    "crossvalidation = KFold(n_splits=10,shuffle=False)\n",
    "\n",
    "for i in range(1,11):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    X_current = poly.fit_transform(X)\n",
    "    model = lm.fit(X_current, y)\n",
    "    scores = cross_val_score(model, X_current, y, scoring=\"neg_mean_squared_error\", cv=crossvalidation, n_jobs=1)\n",
    "    print(\"Degree-\"+str(i)+\" polynomial MSE: \" + str(np.mean(np.abs(scores))) + \", STD: \" + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation time is shorter for kCV as compared to LOOCV. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3.4 The Bootstrap\n",
    "\n",
    "In this method we repeatedly sample observations from the original dataset to obtain distinct datasets. The sampling is performed with replacement - the same observation can occur more than once in the bootstrap dataset.\n",
    "\n",
    "Bootstrapping does not assume the distribution of the data, it simply simulates multiple samples of the data with replacement. The required parameters, such as mean, variance are calcluated from the histogram of these values of each sample subset.\n",
    "\n",
    "Suppose we have one predictor variable and two response variables $X$ and $Y$, and we choose a fraction $\\alpha$ of the predictor variable for $X$ and $1-\\alpha$ for $Y$. We want to minimize the total variance of $\\alpha$, i.e $Var(\\alpha*X + (1-\\alpha)*Y)$. This value of alpha is given by:\n",
    " $$\\alpha = \\frac{\\sigma_Y^2 - \\sigma_{XY}}{\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}}$$\n",
    "\n",
    "where, $\\sigma_X^2 = Var(X), \\sigma_Y^2 = Var(Y), \\sigma_XY = Cov(X,Y)$\n",
    "\n",
    "We calculate estimates for each of the datasets and compute the standard error of all the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.895251</td>\n",
       "      <td>-0.234924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.562454</td>\n",
       "      <td>-0.885176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417090</td>\n",
       "      <td>0.271888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.044356</td>\n",
       "      <td>-0.734198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.315568</td>\n",
       "      <td>0.841983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.479091</td>\n",
       "      <td>1.454774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.535020</td>\n",
       "      <td>-0.399175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.773129</td>\n",
       "      <td>-0.957175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.403634</td>\n",
       "      <td>1.396038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.588496</td>\n",
       "      <td>-0.497285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X         Y\n",
       "0  -0.895251 -0.234924\n",
       "1  -1.562454 -0.885176\n",
       "2  -0.417090  0.271888\n",
       "3   1.044356 -0.734198\n",
       "4  -0.315568  0.841983\n",
       "..       ...       ...\n",
       "95  0.479091  1.454774\n",
       "96 -0.535020 -0.399175\n",
       "97 -0.773129 -0.957175\n",
       "98  0.403634  1.396038\n",
       "99 -0.588496 -0.497285\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Portfolio = pd.read_csv('Data/Portfolio.csv')\n",
    "Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function alpha that will calculate the alpha as in the equation shown above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use np.cov(X,Y)[0,1] not np.cov as the latter returns a matrix with the variance and covariance.\n",
    "def alpha(X,Y):\n",
    "    return (np.var(Y)-np.cov(X,Y)[0,1])/(np.var(X)+np.var(Y)-2*np.cov(X,Y)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5766511516108046\n"
     ]
    }
   ],
   "source": [
    "X = Portfolio.X[0:100]\n",
    "Y = Portfolio.Y[0:100]\n",
    "print(alpha(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we bootstrap the sample datasets used; we randomly select 100 observations with replacement from the dataset and calculate the $\\alpha$ by recording all the estimates for it and calculating its mean. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5716479267105111\n"
     ]
    }
   ],
   "source": [
    "def bstrap(df):\n",
    "    tresult = 0\n",
    "    for i in range(0,100):\n",
    "        dfsample = df.sample(frac=1, replace=True)\n",
    "        X = dfsample.X[0:100]\n",
    "        y = dfsample.Y[0:100]\n",
    "        result = alpha(X,y)\n",
    "        tresult += result\n",
    "    fresult = tresult / 100\n",
    "    print(fresult)\n",
    "bstrap(Portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bootstrapping explanation: https://statisticsbyjim.com/hypothesis-testing/bootstrapping/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
